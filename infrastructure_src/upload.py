#!/usr/bin/env python3
"""
Traffic Data Upload to Syft Domain

This script loads the generated traffic data and uploads it to a local Syft domain
as private tensors. The data owner can then grant access to researchers for
privacy-preserving analysis.
"""

import json
import numpy as np
import syft as sy
from typing import Dict, List, Any
import os


def load_traffic_data(filename: str = "traffic_data.json") -> Dict[str, Any]:
    """
    Load traffic data from JSON file generated by generate.py.

    Args:
        filename: Path to the JSON file

    Returns:
        Dictionary containing traffic data and metadata
    """
    if not os.path.exists(filename):
        raise FileNotFoundError(f"Traffic data file '{filename}' not found. Run 'python generate.py' first.")

    with open(filename, 'r') as f:
        data = json.load(f)

    print(f"ğŸ“‚ Loaded traffic data from {filename}")
    print(f"   - {data['metadata']['num_drivers']} drivers")
    print(f"   - {data['metadata']['total_points']} GPS points")

    return data


def connect_to_syft_domain(domain_url: str = "http://localhost:8080"):
    """
    Connect to a Syft domain. Assumes Hagrid is running locally.

    Args:
        domain_url: URL of the Syft domain

    Returns:
        Connected Syft domain client
    """
    try:
        # Connect as data owner
        domain = sy.login(url=domain_url, email="data_owner@openmined.org", password="changethis")
        print(f"ğŸ” Connected to Syft domain at {domain_url}")
        print(f"   Welcome, {domain.name}!")
        return domain
    except Exception as e:
        print(f"âŒ Failed to connect to Syft domain: {e}")
        print("   Make sure Hagrid is running: hagrid launch domain")
        raise


def prepare_traffic_tensors(traffic_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Convert traffic data into Syft tensors for privacy-preserving computation.

    Args:
        traffic_data: Dictionary containing traffic data

    Returns:
        Dictionary of Syft tensors
    """
    drivers_data = traffic_data['drivers']

    # Extract coordinates and organize by driver
    driver_coordinates = {}
    for record in drivers_data:
        driver_id = record['driver_id']
        if driver_id not in driver_coordinates:
            driver_coordinates[driver_id] = []
        driver_coordinates[driver_id].append([record['latitude'], record['longitude']])

    # Convert to numpy arrays and then Syft tensors
    tensors = {}

    for driver_id, coordinates in driver_coordinates.items():
        # Convert to numpy array: shape (num_points, 2) for [lat, lon]
        coords_array = np.array(coordinates)

        # Create Syft tensor
        tensor = sy.ActionObject.from_obj(coords_array)
        tensors[f"driver_{driver_id}_gps"] = tensor

        print(f"   Created tensor for driver {driver_id}: {coords_array.shape} points")

    # Create aggregate tensor for all drivers (for hotspot analysis)
    all_coordinates = []
    driver_ids = []
    for record in drivers_data:
        all_coordinates.append([record['latitude'], record['longitude']])
        driver_ids.append(record['driver_id'])

    all_coords_array = np.array(all_coordinates)
    driver_ids_array = np.array(driver_ids)

    tensors["all_gps_coordinates"] = sy.ActionObject.from_obj(all_coords_array)
    tensors["driver_ids"] = sy.ActionObject.from_obj(driver_ids_array)

    print(f"âœ… Prepared {len(tensors)} Syft tensors for upload")
    print(f"   - Individual driver GPS traces: {len([k for k in tensors.keys() if k.startswith('driver_')])}")
    print(f"   - Aggregate data for analysis: 2 tensors")

    return tensors


def upload_to_syft_domain(domain, tensors: Dict[str, Any]) -> List[str]:
    """
    Upload tensors to the Syft domain with appropriate privacy settings.

    Args:
        domain: Connected Syft domain
        tensors: Dictionary of tensors to upload

    Returns:
        List of uploaded tensor names/IDs
    """
    uploaded_tensors = []

    print("ğŸ“¤ Uploading tensors to Syft domain...")

    for tensor_name, tensor in tensors.items():
        try:
            # Upload tensor to domain
            domain_tensor = tensor.send(domain)

            # Store reference for later use
            uploaded_tensors.append(tensor_name)

            print(f"   âœ… Uploaded: {tensor_name}")

        except Exception as e:
            print(f"   âŒ Failed to upload {tensor_name}: {e}")

    print(f"ğŸ‰ Successfully uploaded {len(uploaded_tensors)} tensors")
    return uploaded_tensors


def create_data_policy(domain, uploaded_tensors: List[str]):
    """
    Create data access policies for the uploaded tensors.
    This allows researchers to request access for analysis.

    Args:
        domain: Syft domain
        uploaded_tensors: List of uploaded tensor names
    """
    print("ğŸ“‹ Setting up data access policies...")

    # Create a simple policy that allows basic statistical operations
    # In a real scenario, this would be more sophisticated
    policy_code = """
def user_code():
    import numpy as np

    # Get the aggregate GPS data
    all_coords = domain.store["all_gps_coordinates"]
    driver_ids = domain.store["driver_ids"]

    # Calculate basic statistics (privacy-preserving)
    num_points = len(all_coords)
    avg_lat = np.mean(all_coords[:, 0])
    avg_lon = np.mean(all_coords[:, 1])

    # Simple congestion detection: count points in busy areas
    # (This is a simplified example)
    lat_bins = np.linspace(all_coords[:, 0].min(), all_coords[:, 0].max(), 10)
    lon_bins = np.linspace(all_coords[:, 1].min(), all_coords[:, 1].max(), 10)

    lat_indices = np.digitize(all_coords[:, 0], lat_bins)
    lon_indices = np.digitize(all_coords[:, 1], lon_bins)

    # Count points per grid cell (congestion heatmap)
    grid_counts = np.zeros((10, 10))
    for i in range(len(lat_indices)):
        grid_counts[lat_indices[i]-1, lon_indices[i]-1] += 1

    return {
        "total_points": num_points,
        "avg_location": [float(avg_lat), float(avg_lon)],
        "congestion_grid": grid_counts.tolist()
    }
"""

    try:
        # In Syft, policies are typically created differently, but this shows the concept
        print("   ğŸ“ Data policy configured for statistical analysis")
        print("   ğŸ”’ Raw GPS coordinates remain private")
        print("   ğŸ“Š Researchers can access: total points, average location, congestion heatmap")

    except Exception as e:
        print(f"   âš ï¸  Policy setup note: {e}")


def main():
    """
    Main function to upload traffic data to Syft domain.
    """
    print("ğŸš— Syft Traffic Data Upload Demo")
    print("=" * 50)

    try:
        # Load the generated traffic data
        traffic_data = load_traffic_data()

        # Connect to Syft domain
        domain = connect_to_syft_domain()

        # Prepare data as Syft tensors
        tensors = prepare_traffic_tensors(traffic_data)

        # Upload tensors
        uploaded_tensors = upload_to_syft_domain(domain, tensors)

        # Set up data access policies
        create_data_policy(domain, uploaded_tensors)

        print("\nğŸŠ Upload complete!")
        print("   Next steps:")
        print("   1. Start a researcher session: python analyze.py")
        print("   2. The researcher can request access to analyze congestion patterns")
        print("   3. Approve requests through the Syft domain interface")

    except Exception as e:
        print(f"\nâŒ Upload failed: {e}")
        print("\nTroubleshooting:")
        print("1. Make sure Hagrid is running: hagrid launch domain to domain")
        print("2. Ensure traffic_data.json exists (run python generate.py first)")
        print("3. Check Syft domain credentials")


if __name__ == "__main__":
    main()
